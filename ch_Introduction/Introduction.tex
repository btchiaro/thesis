\chapter{Introduction}\label{ch:introduction}
%\section{Quantum information overview and motivation}
\section{Historical context}

In 1926 Erwin Schr\"odinger proposed a wave theory governing the dynamics of microscopic systems.\cite{Schrodinger1926}
In the succeedng years, quantum mechanics would prove to be extraordinarily accurate in predicting the subtle and surprising behavior of electrons, photons, and atoms alike.
Despite the success of the theory,
the resulting equations developed a reputation for being unmanagable with only the simplest cases being exactly solvable.
For this reason, approximation schemes have been an essential part of quantum physics since the early days.  %Since the early days of quantum mechanics approximation schemes have been essential to progress.
With the developement of computers,
numerical methods have become among the most important of these approximation schemes when applying quantum theory to real physical systems.
The challenge is that for all but the simplest systems the computational resources required are immense.

For this reason, people have long considered how to efficiently simulate quantum systems using computers.
In 1982, in a lecture that could be considered the birth of quantum simulation,
Richard Feynman suggested that quantum systems could be efficiently simulatable using quantum computational resources.\cite{Feynman1982}
\draftcomment{
This is the first and most obvious motivation for developing a quantum computer,
though the vigorous development of quantum information theory has provided many others.\cite{MikeandIke, Shor, Grover}
In principle, any quantum mechanical system could serve as the basis for a quantum computer.
Numerous teams have demonstrated great progress toward that goal using such physical systems as trapped ions,
defect spins, neutral atoms, among others.
} % end draftcomment
An insight that arose not long after Feynman's was that the relevance of quantum mechanics is not limited to microscopic objects.
John Martinis observed that macroscopic electrical circuits can also behave quantum mechanically and thus form the basis of a superconducting quantum processor.\cite{Martinis1985}
The superconducting quantum bit (qubit), a controllable, macroscopic two level system was demonstrated in 1999. \cite{Nakamura1999}

Since that demonstration superconducting qubit architectures have continuously improved qubit performance and increased the number of qubits in a processor.
This progress culminated in the achievement of quantum supremacy in 2019,
when a superconducting quantum processor performed a well defined computational task that is not possible to perform on a modern classical supercomputer.\cite{Arute2019}
This achievement heralds the onset of an era in which quantum resources can meaningfully contribute to computational tasks considered intractable on classical hardware alone.
It is likely that many of the early contributions of quantum computers will be to understanding the behavior of quantum systems,
as was originally envisioned by Feynman.
In that spirit,
the final chapter of this thesis uses a quantum processor as a programmable quantum simulator to probe the entanglement dynamics of a many-body localized system.
%The original design known as the Cooper-pair box

\indraftprogress{
In 2007 the transmon circuit was proposed as a device that should have better coherence. \cite{Koch2007}
\indraftprogress{This was demonstrated on 2011\cite{Paik2011}}
A planar version of the transmon circuit, compatible with modern microprocessing techniques and suitable for scaling to many-qubit systems was demonstrated not long after.\cite{Barends2013}
The following year a variant on the transmon featuring a tunable inter-qubit strength was developed.\cite{Chen2014}
This circuit is the basis for the processor that we use to probe many-body localization in the last chapter of this thesis.
The latest milestone in the developement of superconducting qubits is the achievement of quantum supremacy.\cite{Arute2019}
We have now demonstrated a decisive quantum computational advantage over a classical supercomputer,
which heralds the onset of an era in which quantum resources can meaningfully contribute to tasks considered intractable to classical hardware alone.
} % end indraftprogress
\draftcomment{Origins of quantum mechanics?  Not sure if to include this but \cite{Einstein photo electric, Shrodinger1926, Heisenberg, von Neumann, Born}
Circuits behave quantum mechanically, macroscopic quantum tunneling \cite{MartinisThesis}
Demonstration of a superconducting qubit \cite{Nakamura1999}, could \cite{Martinis Rabi}
Josephson Junction \cite{Josephson1962}
Development of the transmon \cite{Koch2007}
Demonstration of 3d transmon \cite{Paik2011}
Quantum information \cite{Mike and Ike}
Algorithms \cite{Shor, Grover, ...}
Planar transmon \cite{Barends2013}
Gmon \cite{Chen2014}
Quantum suppremacy \cite{Arute2019}
}

\section{What is a qubit and why is it powerful?}
Whereas one classical bit of information can be represented as either 0 or 1, the state of a single ideal qubit can be represented as a vector pointing to the surface of a sphere.
This sphere is referred to as the Bloch sphere, and provides excellent physical intuition for the behavior of a qubit.
% TODO Graphic of Bloch sphere
\quickwidefig{0.8\columnwidth}{./PDF/sch_bloch_sphere_190902_1237p.pdf}
{\textbf{Bloch sphere representation of the single qubit density matrix}.
The states $\ket{\psi} = \cos \left( \frac{\theta}{2} \right) \ket{0} + e^{i \phi} \sin \left( \frac{\theta}{2} \right)\ket{1}$ for
$\theta \in [0, \pi]$ and $\phi \in [0, 2 \pi]$ are on the surface of the Bloch sphere.
The ground state $\ket{0}$ and excited state $\ket{1}$ are located at the North and South poles.
}
{SchemBlochSphere}

The points at the North and South poles of the Block sphere correspond to the logical $\ket{0}$ and $\ket{1}$.
The points away from the poles have amplitude in both the $\ket{0}$ state and the $\ket{1}$ state and are said to be "in superposition".
The Bloch sphere is in fact the graphic representation of the single qubit Hilbert space.
The Bloch vector is a vector pointing from the center of the sphere and represents the single qubit density matrix.
The Bloch vector is commonly decomposed as
\qeqn{ \rho = \frac{1}{2} \left( I + \vec{a} \cdot \vec{\sigma} \right) }
where $a$ = $[\sigma^x, \sigma^y, \sigma^z]$ is a vector of Pauli matrices and $a  = \left[\expect{\sigma^x}, \expect{\sigma^y}, \expect{\sigma^z} \right]$ is a vector of their expectation values.
Points on the surface of the sphere correspond to pure states and can be written in the form:
\qeqn{ \hat{\rho} = \ket{\psi} \bra{\psi} }
Points on the inside of the sphere correspond with mixed states and can be written as:
\qeqn{  \sum_i p_i \ket{\psi_i} \bra{\psi_i} }

The distinction between pure states and mixed states is best thought of in terms of von Neumann entropy
\qeqn{S_{vN} = - \text{Tr} \, \rho \, \text{log} \, \rho}

The von Neumann entropy quantifies the degree of entanglement with all external degrees of freedom.
Pure states are those that have zero von Neumann entropy indicating a lack of entanglement with their environment,
while mixed states of $N$ qubits have a von Neumann entropy $\leq N \log 2$.
Further discussion of entanglement entropy is at the heart of chapter 5.

The ability to encode superposition and mixed states in a single quantum bit suggests that quantum bits provide a means for higher density information encoding than is possible with their classical counterparts.
After all the complete description a pure qubit state requires the specification of $\theta$ and $\phi$, two continuous variables,
rather than the simple one or zero description of a classical bit.
However, the true power of a quantum processor comes from the way that multiple qubits combine.
For a system of qubits each in a pure state, the state of the composite system is described by the tensor product of the constituent wave vectors.
For example, if two qubits a and b are each in a superposition state on the equator of the Bloch sphere:
$\ket{\psi_a} = \frac{\ket{0}+\ket{1}}{\sqrt{2}}$ and $\ket{\psi_b} = \frac{\ket{0}+\ket{1}}{\sqrt{2}}$
then the state of the full a,b system is
$\ket{\psi_{ab}} = \ket{\psi_a} \otimes \ket{\psi_b} = \frac{1}{2} \left( \ket{00} + \ket{01} + \ket{10} + \ket{11} \right)$.

The fact that quantum systems combine in this way leads directly to the exponential scaling of the power of a quantum processor.
Whereas a two bit classical processor can represent one of the states $\ket{00}$, $\ket{01}$, $\ket{10}$, or $\ket{11}$,
the quantum processor is able to represent them all simultaineously, each with a relative amplitude and phase!
The straight forward, but amazing, result is that, roughly speaking, in order to double the capacity of a classical processor you would need to double the number of classical bits.
In contrast, if you wish to double the capacity of the quantum processor you only need to add one more qubit.
The advantages of the quantum computer over it's classical counterpart arise from this ability to store and process exponentially more information in an intrinsically parallel way.

%In fact, the capacity of the quantum register is scaling exponentially in the number of qubits in contrast to the classical processor which is scaling linearly.

\indraftprogress{
\section{applications}
While it is true that not every computational problem can take advantage of quantum resources, there are several cases where a quantum speedup has been proven to exist.

Shor's algorithm for factoring large numbers has been proven to give an exponential speedup

Grover's algorithm for search has only a polynomial speedup.

Other promsing areas of research rely on the efficiency of using the quantum computer to efficiently solve problems in quantum dynamics.
Optimization problems of such as the "Travelling salesman" are an example of this.
Since these problems can be mapped to finding the groundstate of an Ising spin lattice,
we can expect to realize a quantum speedup by simply producing our desired Ising lattice and allowing the system to decay to it's ground state and simply measuring this state.

In this thesis we take a very direct approach.
Directly computing quantum dynamics is a computationally hard problem.
In order to make a brute force solution to a quantum dynamics problem, you need to time evolve the wave function under a Hamiltonian.

% TODO write the schrodinger equation
The Exponentiation of a matrix with linear dimension is scaling exponentially in the number of qubits, is intractible for even a few tens of qubits.

% Table Hilbert space size for N 2-level, and 3-level systems ... Maybe fixed photon etc. (Classical memory required)
This is essentially what Feynman had in mind when he proposed using quantum resources to simulate quantum systems.
In 198x Feynman proposed using quantum resources to simulate quantum processes.

This is because, as discussed above, the Hilbert space of the system is growing exponentally in the number of qubits.
Classical methods rely on matrix exponentiation / exact diagonalization.
Additionally, there are several.

\subsection{Implementations of analog}
In principle any controllable and well isolated quantum system can be used as a platform for quantum computation.
Indeed, early processors have been demonstrated in a variety of formats.

- Spins (NV)
- Trapped ions
- Lukin (Rydberg)
- Cold atoms for quantum simulation
- Superconducting qubits
} %end indraftprogress

\section{Challenges}
Although there is great promise in quantum computing, there are challenges that must be overcome before a quantum computer can be realized.
Foremost among these challenges is that the information in a quantum computer is unstable.
The errors arising from this instability can be roughly categorized into two main categories: relaxation and dephasing.
These are illustrated in Fig.~\ref{schem relaxation dephasing}
Relaxation events as illustrated in Fig.~\ref{schem relaxation dephasing}(a), arise when energy is lost from the qubit system.
Errors of this variety arise, for example, when a computational photon is absorbed by a parasitic two-level system (TLS).
An example of characterizing this type of dissipation is provided in chapter 4.
Dephasing, as illustrated in Fig.~\ref{schem relaxation dephasing}(b),
results from an increasing uncertainty in the relative phase between the $\ket{0}$ state and $\ket{1}$ state of the qubit.
Errors of this variety arise, for example, as the energy difference between $\ket{0}$ state and $\ket{1}$ state fluctuates in response to random,
time varying, magnetic fields.
\rd{An example of characterizing these qubit energy fluctuations is found in the appendix}


% TODO Add data for T1 and dephasing (p1 vs time, rho vs time for Ramsey experiments)
\quickwidefig{\columnwidth}{./PDF/sch_relaxation_dephasing_190902_1238p.pdf}
{
a) Schematic of relaxation.  Over time the excited state of the qubit $\ket{1}$ tends to decay to the ground state $\ket{0}$ causing a logical error.
b) Schematic of dephasing.  Over time uncertainty in the phase between the $\ket{1}$ and $\ket{0}$ states grows.
}
{schem relaxation dephasing}

\draftcomment{
In our effort to construct a quantum computer out of superconducting qubits measuring and mitigating these error mechanisms is a primary research direction.
In this thesis we explore several aspects of this coherence engineering before demonstrating before providing an algorithm demonstration that where we
use a supreconducting qubit system to address a modern question in condensed matter physics: Entanglement growth in the Manybody-localized phase.
Material science (Chapter 3)
Device design and fabrication (Chapter 4)
Dephasing metrology (chapter 5)
}

\section{Overview of this thesis}
In this thesis we share contributions to the development of a superconducting quantum processor
and demonstrate the use of one as a programmable quantum simulator as we use it to probe the phenomenon of Many-body localization.
In chapter 2, we summarize the essential theory necessary to understand the experiments in the later chapters.
In chapter 3, we contribute to the basic materials used to construct a quantum processor by investigating Titanium Nitride,
a high kinetic inductance compound superconductor, with excellent coherence properties if made correctly.
In chapter 4, we contribute a device characterization where we isolate the excess dielectric loss due to the incorporation of flux trapping hole arrays.
These flux traps are commonly used to protect from magnetic vortex loss, but may introduce excess dielectric loss.
This is an important consideration as we strive for the longest coherence times posiible.
Finally, in chapter 5, we contribute a system level algorithm demonstration where we use a $9$ qubit, nearest-neighbor coupled,
linear chain device, featuring tunable qubit frequencies and tunable interqubit coupling to compute the entanglement dynamics of an interacting, localized system.
